---
trigger: model_decision
---

This includes the v2 of the plan that was blurry before, v3 would be more latest but we need to have more understanding of v2 to move on to v3 of the plans

# Vansales Connector 2.0 - Revised Architecture

## Hybrid Cloud + On-Premise Design with Mini Connectors

**Date:** January 29, 2026  
**Version:** 2.0 - REVISED  
**Status:** Architecture Revision - Critical Update

---

## Executive Summary

### The Critical Missing Piece

The original architecture assumed all ERP systems would be:

- ✅ Cloud-hosted or internet-accessible
- ✅ Have static IP addresses
- ✅ Allow direct inbound connections

**Reality Check:**

- ❌ 70% of SMB ERP systems are on-premise
- ❌ Dynamic IPs behind NAT/firewalls
- ❌ No inbound access permitted by IT policies
- ❌ Cannot punch holes in corporate firewalls

### The Solution: Mini Connector Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                    CONNECTOR CONSOLE (Cloud)                     │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │              Aggregator Marketplace                         │ │
│  │  [Vansales] [Salesforce] [SAP] [Oracle] [Snowflake] [...]  │ │
│  └────────────────────────────────────────────────────────────┘ │
│                                                                  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐         │
│  │  Workflow    │  │  AI SDK      │  │  Data Buffer │         │
│  │  Designer    │  │  Generator   │  │  (Temp Hold) │         │
│  └──────────────┘  └──────────────┘  └──────────────┘         │
│                                                                  │
│           WebSocket Gateway (wss://)                            │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         │ Outbound WebSocket Connection
                         │ (Mini Connector initiates)
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│ Mini         │  │ Mini         │  │ Mini         │
│ Connector A  │  │ Connector B  │  │ Connector C  │
│ (API: xxx1)  │  │ (API: xxx2)  │  │ (API: xxx3)  │
└──────┬───────┘  └──────┬───────┘  └──────┬───────┘
       │                 │                 │
       │ Local Access    │                 │
       ▼                 ▼                 ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│   SAP ERP    │  │  Tally ERP   │  │ MySQL Local  │
│ (localhost)  │  │ (10.0.0.5)   │  │ (127.0.0.1)  │
└──────────────┘  └──────────────┘  └──────────────┘
   Company A         Company B          Company C
```

### Key Changes from Original Architecture

|Aspect|Original|Revised|
|---|---|---|
|**Connection Model**|Cloud → ERP (inbound)|Mini Connector → Cloud (outbound)|
|**Network Requirements**|Static IP + firewall rules|Only outbound HTTPS/WSS|
|**Deployment**|Cloud-only|Hybrid (Cloud Console + On-Prem Mini)|
|**Data Flow**|Direct cloud execution|Via Mini Connector proxy|
|**Security**|Direct credential storage|API Key + Local credential isolation|
|**Installation**|N/A|Download .exe/.zip per connector|

---

## Table of Contents

1. [Problem Space - Updated Reality](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#1-problem-space)
2. [Architecture Overview](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#2-architecture-overview)
3. [Component Breakdown](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#3-component-breakdown)
4. [Data Flow Patterns](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#4-data-flow-patterns)
5. [Security Model](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#5-security-model)
6. [Implementation Plan](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#6-implementation-plan)
7. [Technology Stack](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#7-technology-stack)
8. [Critical Design Decisions](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#8-critical-design-decisions)
9. [Production Checklist](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#9-production-checklist)
10. [Risk Assessment](https://claude.ai/chat/d01fff7c-0550-429a-ae92-dc38f0278c30#10-risk-assessment)

---

## 1. Problem Space - Updated Reality

### The Boss's Flow (Verbatim Requirements)

1. **Connector Console** = Cloud admin interface
    
    - Shows aggregator marketplace
    - Vansales Connector is one aggregator among many
    - Can add Salesforce, SAP Cloud, Snowflake, etc.
2. **Mini Connector** = On-premise agent
    
    - Connects to console via WebSocket (outbound only)
    - One API key = One mini connector instance
    - Attempts to use same API key = Error
    - Acts as a server that opens WebSocket to cloud
3. **Workflow Creation** (Cloud)
    
    - Design workflows in console
    - DB access defaults to READ-ONLY mode
    - Even if root credentials provided, enforce READ-ONLY
    - SDK code must execute in enclosed VM/WASM sandbox
4. **Schema Understanding**
    
    - Console must understand DB schema from credentials
    - Auto-discover tables, columns, relationships
    - Use for AI-powered workflow suggestions
5. **Documentation-Based SDK Generation**
    
    - Add URL of source/destination documentation
    - AI reads docs and generates SDK
    - SDK becomes available in cloud for workflow building
    - Dynamic in nature (regenerate when docs change)
6. **Aggregator Installation**
    
    - List aggregator in marketplace
    - Install by API key per company/account
    - Once installed, see documentation
    - Create workflows based on aggregator capabilities

### Real-World Scenarios

#### Scenario 1: Local Tally ERP (Small Business)

```
Problem:
- Tally ERP running on Windows desktop (192.168.1.100)
- No public IP, behind home router
- Owner wants to sync to Shopify

Solution:
1. Download Mini Connector .exe
2. Install on same network as Tally
3. Enter API key from console
4. Mini Connector connects to cloud via WebSocket
5. Cloud sends "extract customers" command
6. Mini Connector queries local Tally DB
7. Returns data to cloud buffer
8. Cloud pushes to Shopify
```

#### Scenario 2: On-Premise SAP (Enterprise)

```
Problem:
- SAP ECC on corporate network (10.0.50.10)
- Strict firewall policy (no inbound connections)
- Needs to sync to Snowflake nightly

Solution:
1. IT downloads Mini Connector .zip
2. Deploy on internal server with SAP access
3. Configure with READ-ONLY SAP credentials
4. Mini Connector establishes persistent WebSocket
5. Cloud schedules nightly workflow
6. Mini Connector executes queries locally
7. Streams data to cloud buffer
8. Cloud loads to Snowflake
```

#### Scenario 3: Hybrid (Cloud Source → On-Prem Destination)

```
Problem:
- Salesforce (cloud) → Local PostgreSQL (on-prem)
- PostgreSQL not exposed to internet

Solution:
1. Salesforce = Direct aggregator (cloud-to-cloud)
2. PostgreSQL = Mini Connector (on-prem)
3. Workflow: Extract from Salesforce (direct)
4. Transform in cloud
5. Send to Mini Connector via WebSocket
6. Mini Connector writes to local PostgreSQL
```

---

## 2. Architecture Overview

### Three-Layer Architecture

```
┌───────────────────────────────────────────────────────────────────┐
│                      LAYER 1: CLOUD CONSOLE                        │
│  ┌──────────────────────────────────────────────────────────────┐ │
│  │                  Aggregator Marketplace                       │ │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐        │ │
│  │  │Vansales  │ │Salesforce│ │ Snowflake│ │  Custom  │  ...   │ │
│  │  │Connector │ │   API    │ │   API    │ │   API    │        │ │
│  │  └──────────┘ └──────────┘ └──────────┘ └──────────┘        │ │
│  └──────────────────────────────────────────────────────────────┘ │
│                                                                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │  Workflow   │  │  AI SDK     │  │  Execution  │              │
│  │  Designer   │  │  Generator  │  │  Orchestrator│              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│                                                                    │
│  ┌────────────────────────────────────────────────────────────┐  │
│  │              WebSocket Gateway (WSS)                        │  │
│  │  - Connection Registry                                      │  │
│  │  - Command Queue (per connection)                           │  │
│  │  - Heartbeat Monitor                                        │  │
│  └────────────────────────────────────────────────────────────┘  │
│                                                                    │
│  ┌────────────────────────────────────────────────────────────┐  │
│  │              Temporary Data Buffer                          │  │
│  │  - Encrypted at rest (AES-256)                             │  │
│  │  - TTL: 24 hours (auto-purge)                              │  │
│  │  - Per-workflow isolation                                   │  │
│  └────────────────────────────────────────────────────────────┘  │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             │ Outbound WebSocket (wss://)
                             │ Initiated by Mini Connector
                             │
┌────────────────────────────┴───────────────────────────────────────┐
│                   LAYER 2: MINI CONNECTOR (On-Premise)             │
│                                                                     │
│  ┌──────────────────────────────────────────────────────────────┐ │
│  │              Mini Connector Application                       │ │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐        │ │
│  │  │WebSocket │ │ Command  │ │ Executor │ │  Local   │        │ │
│  │  │ Client   │ │  Parser  │ │  Engine  │ │  Vault   │        │ │
│  │  └──────────┘ └──────────┘ └──────────┘ └──────────┘        │ │
│  └──────────────────────────────────────────────────────────────┘ │
│                                                                     │
│  Configuration:                                                     │
│  - API Key (unique, non-reusable)                                 │
│  - Cloud Endpoint (wss://connector.vansales.com)                  │
│  - Local Credentials (encrypted, never sent to cloud)             │
│  - Connection Settings (retry, timeout, buffer size)               │
│                                                                     │
└────────────────────────────┬───────────────────────────────────────┘
                             │
                             │ Local Network / Localhost
                             │
┌────────────────────────────┴───────────────────────────────────────┐
│                   LAYER 3: TARGET SYSTEMS (On-Premise)             │
│                                                                     │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐          │
│  │   SAP    │  │  Tally   │  │  MySQL   │  │PostgreSQL│          │
│  │   ERP    │  │   ERP    │  │  Local   │  │  Local   │          │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘          │
│                                                                     │
│  Access: localhost, 127.0.0.1, or local network IPs               │
│  Credentials: Stored locally in Mini Connector (encrypted)         │
│  Network: No inbound connections required                          │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. Component Breakdown

### 3.1 Cloud Console (Layer 1)

#### A. Aggregator Marketplace

**Purpose:** Central hub for all data connectors

**Structure:**

```typescript
interface Aggregator {
  id: string;
  name: string;
  type: 'cloud' | 'on-premise' | 'hybrid';
  icon: string;
  description: string;
  
  // Documentation
  documentationUrl?: string;
  apiDocsUrl?: string;
  
  // Capabilities
  capabilities: {
    read: boolean;
    write: boolean;
    bulk: boolean;
    streaming: boolean;
    webhooks: boolean;
  };
  
  // SDK
  sdkStatus: 'not-generated' | 'generating' | 'ready' | 'failed';
  sdkVersion?: number;
  
  // Installation
  requiresMiniConnector: boolean;
  installationInstructions: string;
  
  // Metadata
  category: 'erp' | 'crm' | 'warehouse' | 'database' | 'custom';
  popularity: number;
  verified: boolean;
}

// Example aggregators
const MARKETPLACE: Aggregator[] = [
  {
    id: 'vansales-connector',
    name: 'Vansales Connector',
    type: 'on-premise',
    requiresMiniConnector: true,
    capabilities: { read: true, write: true, bulk: true, streaming: true },
    category: 'erp'
  },
  {
    id: 'salesforce',
    name: 'Salesforce API',
    type: 'cloud',
    requiresMiniConnector: false,
    capabilities: { read: true, write: true, webhooks: true },
    category: 'crm'
  },
  {
    id: 'snowflake',
    name: 'Snowflake Data Warehouse',
    type: 'cloud',
    requiresMiniConnector: false,
    capabilities: { read: true, write: true, bulk: true },
    category: 'warehouse'
  }
];
```

**API Endpoints:**

```typescript
// List aggregators
GET /api/v1/aggregators
Response: Aggregator[]

// Install aggregator for tenant
POST /api/v1/tenants/{tenantId}/aggregators/{aggregatorId}/install
Request: {
  credentials?: Record<string, string>, // For cloud aggregators
  documentationUrl?: string,
  customConfig?: Record<string, any>
}
Response: {
  installationId: string,
  apiKey?: string, // For on-premise (mini connector)
  downloadUrl?: string, // Mini connector executable
  status: 'pending' | 'ready'
}

// Generate SDK from documentation
POST /api/v1/aggregators/{aggregatorId}/generate-sdk
Request: {
  documentationUrl: string,
  apiDocsUrl?: string
}
Response: {
  sdkVersion: number,
  status: 'generating' | 'ready' | 'failed',
  jobId: string
}

// Get aggregator capabilities
GET /api/v1/aggregators/{aggregatorId}/capabilities
Response: {
  operations: Operation[], // read, write, query, etc.
  schema?: DatabaseSchema // If schema was discovered
}
```

#### B. WebSocket Gateway

**Purpose:** Persistent connections to Mini Connectors

**Architecture:**

```typescript
class WebSocketGateway {
  // Connection registry (Redis-backed)
  private connections = new Map<string, WebSocketConnection>();
  
  interface WebSocketConnection {
    apiKey: string;
    tenantId: string;
    socket: WebSocket;
    connectedAt: Date;
    lastHeartbeat: Date;
    status: 'connected' | 'disconnected' | 'error';
    commandQueue: CommandQueue;
  }
  
  // Connection lifecycle
  async onConnect(socket: WebSocket, apiKey: string) {
    // 1. Validate API key
    const config = await this.validateApiKey(apiKey);
    
    // 2. Check for duplicate connections
    if (this.connections.has(apiKey)) {
      socket.send(JSON.stringify({
        type: 'error',
        message: 'API key already in use. Only one connection per key allowed.'
      }));
      socket.close(4001, 'Duplicate connection');
      return;
    }
    
    // 3. Register connection
    this.connections.set(apiKey, {
      apiKey,
      tenantId: config.tenantId,
      socket,
      connectedAt: new Date(),
      lastHeartbeat: new Date(),
      status: 'connected',
      commandQueue: new CommandQueue()
    });
    
    // 4. Send welcome message
    socket.send(JSON.stringify({
      type: 'connected',
      message: 'Mini Connector authenticated',
      tenantId: config.tenantId
    }));
    
    // 5. Send queued commands (if any)
    await this.flushCommandQueue(apiKey);
    
    // 6. Log event
    await this.auditLog.log({
      tenantId: config.tenantId,
      action: 'mini_connector_connected',
      apiKey: apiKey.substring(0, 8) + '***'
    });
  }
  
  async onMessage(apiKey: string, message: any) {
    const conn = this.connections.get(apiKey);
    if (!conn) return;
    
    switch (message.type) {
      case 'heartbeat':
        conn.lastHeartbeat = new Date();
        break;
        
      case 'execution_result':
        await this.handleExecutionResult(apiKey, message.data);
        break;
        
      case 'error':
        await this.handleError(apiKey, message.error);
        break;
        
      case 'schema_discovery':
        await this.handleSchemaDiscovery(apiKey, message.schema);
        break;
    }
  }
  
  async onDisconnect(apiKey: string) {
    const conn = this.connections.get(apiKey);
    if (!conn) return;
    
    conn.status = 'disconnected';
    this.connections.delete(apiKey);
    
    await this.auditLog.log({
      tenantId: conn.tenantId,
      action: 'mini_connector_disconnected',
      apiKey: apiKey.substring(0, 8) + '***'
    });
  }
  
  // Send command to Mini Connector
  async sendCommand(apiKey: string, command: Command): Promise<void> {
    const conn = this.connections.get(apiKey);
    
    if (!conn || conn.status !== 'connected') {
      // Queue for later delivery
      await this.commandQueue.enqueue(apiKey, command);
      throw new Error('Mini Connector not connected. Command queued.');
    }
    
    conn.socket.send(JSON.stringify({
      type: 'command',
      commandId: command.id,
      payload: command
    }));
  }
  
  // Heartbeat monitor (runs every 30s)
  private startHeartbeatMonitor() {
    setInterval(() => {
      for (const [apiKey, conn] of this.connections) {
        const secondsSinceHeartbeat = 
          (Date.now() - conn.lastHeartbeat.getTime()) / 1000;
        
        if (secondsSinceHeartbeat > 60) {
          // Consider dead, close connection
          conn.socket.close(4002, 'Heartbeat timeout');
          this.onDisconnect(apiKey);
        }
      }
    }, 30000);
  }
}
```

**WebSocket Protocol:**

```typescript
// Client → Server (Mini Connector → Cloud)
type ClientMessage =
  | { type: 'heartbeat' }
  | { type: 'execution_result'; executionId: string; result: any }
  | { type: 'error'; executionId: string; error: string }
  | { type: 'schema_discovery'; schema: DatabaseSchema }
  | { type: 'status'; status: 'ready' | 'busy' | 'error' };

// Server → Client (Cloud → Mini Connector)
type ServerMessage =
  | { type: 'connected'; tenantId: string }
  | { type: 'command'; commandId: string; payload: Command }
  | { type: 'cancel'; executionId: string }
  | { type: 'shutdown'; reason: string };

interface Command {
  id: string;
  executionId: string;
  type: 'execute_query' | 'discover_schema' | 'test_connection' | 'health_check';
  payload: {
    operation: string;
    params: Record<string, any>;
    timeout?: number;
    retryPolicy?: RetryPolicy;
  };
}
```

#### C. Temporary Data Buffer

**Purpose:** Temporarily store data between extraction and loading

**Design Principles:**

1. **Short-lived:** Data auto-purges after 24 hours
2. **Encrypted:** AES-256 encryption at rest
3. **Isolated:** Per-workflow, per-execution separation
4. **Audited:** All access logged

**Storage Structure:**

```
s3://vansales-buffer/
  tenants/{tenant_id}/
    workflows/{workflow_id}/
      executions/{execution_id}/
        activities/{activity_id}/
          data.json.enc (encrypted)
          metadata.json
          created_at.txt
          ttl.txt (expires_at timestamp)
```

**Buffer Service:**

```typescript
class DataBufferService {
  async store(
    tenantId: string,
    executionId: string,
    activityId: string,
    data: any
  ): Promise<string> {
    // 1. Encrypt data
    const encrypted = await this.encrypt(tenantId, JSON.stringify(data));
    
    // 2. Store in S3 with TTL
    const key = this.generateKey(tenantId, executionId, activityId);
    await this.s3.putObject({
      Bucket: 'vansales-buffer',
      Key: key,
      Body: encrypted,
      Metadata: {
        tenant_id: tenantId,
        execution_id: executionId,
        created_at: new Date().toISOString(),
        expires_at: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString()
      },
      ServerSideEncryption: 'AES256'
    });
    
    // 3. Schedule auto-purge (24h)
    await this.schedulePurge(key, 24 * 60 * 60);
    
    // 4. Audit log
    await this.auditLog.log({
      tenantId,
      action: 'data_buffered',
      executionId,
      activityId,
      size: Buffer.byteLength(encrypted)
    });
    
    return key;
  }
  
  async retrieve(
    tenantId: string,
    executionId: string,
    activityId: string
  ): Promise<any> {
    const key = this.generateKey(tenantId, executionId, activityId);
    
    // 1. Check if exists and not expired
    const metadata = await this.s3.headObject({
      Bucket: 'vansales-buffer',
      Key: key
    });
    
    const expiresAt = new Date(metadata.Metadata.expires_at);
    if (Date.now() > expiresAt.getTime()) {
      throw new Error('Data expired and was purged');
    }
    
    // 2. Retrieve and decrypt
    const obj = await this.s3.getObject({
      Bucket: 'vansales-buffer',
      Key: key
    });
    
    const decrypted = await this.decrypt(tenantId, obj.Body);
    
    // 3. Audit log
    await this.auditLog.log({
      tenantId,
      action: 'data_retrieved',
      executionId,
      activityId
    });
    
    return JSON.parse(decrypted);
  }
  
  // Auto-purge expired data (runs hourly)
  private async purgeExpiredData() {
    const now = new Date();
    
    const objects = await this.s3.listObjectsV2({
      Bucket: 'vansales-buffer'
    });
    
    for (const obj of objects.Contents) {
      const metadata = await this.s3.headObject({
        Bucket: 'vansales-buffer',
        Key: obj.Key
      });
      
      const expiresAt = new Date(metadata.Metadata.expires_at);
      if (now > expiresAt) {
        await this.s3.deleteObject({
          Bucket: 'vansales-buffer',
          Key: obj.Key
        });
      }
    }
  }
}
```

#### D. AI SDK Generator (Enhanced)

**New Requirements:**

1. Read documentation from URL
2. Generate SDK for both cloud and on-premise aggregators
3. Handle READ-ONLY enforcement for on-premise
4. Discover and validate schema

**Implementation:**

```typescript
class AISDKGenerator {
  async generateFromDocumentation(
    aggregatorId: string,
    documentationUrl: string,
    type: 'cloud' | 'on-premise'
  ): Promise<SDKVersion> {
    // 1. Fetch documentation
    const docs = await this.fetchDocumentation(documentationUrl);
    
    // 2. AI parses documentation
    const schema = await this.parseDocumentation(docs, type);
    
    // 3. Generate TypeScript SDK
    const code = await this.generateSDKCode(schema, type);
    
    // 4. Add READ-ONLY enforcement (if on-premise)
    const enforcedCode = type === 'on-premise'
      ? this.enforceReadOnly(code)
      : code;
    
    // 5. Security scan
    const securityScan = await this.securityScanner.scan(enforcedCode);
    if (!securityScan.passed) {
      throw new Error(`Security scan failed: ${securityScan.issues}`);
    }
    
    // 6. Compile to WASM
    const wasm = await this.compiler.compile(enforcedCode);
    
    // 7. Test SDK
    const testResults = await this.testSDK(wasm, schema.operations);
    
    // 8. Store artifacts
    const version = await this.storeSDK(aggregatorId, {
      code: enforcedCode,
      wasm,
      schema,
      securityScan,
      testResults,
      type
    });
    
    return version;
  }
  
  private enforceReadOnly(code: string): string {
    // Wrap all write operations with read-only check
    return `
${code}

// READ-ONLY ENFORCEMENT
const ALLOWED_OPERATIONS = ['SELECT', 'SHOW', 'DESCRIBE', 'EXPLAIN'];

function enforceReadOnly(query: string) {
  const operation = query.trim().split(' ')[0].toUpperCase();
  if (!ALLOWED_OPERATIONS.includes(operation)) {
    throw new Error(
      'Write operations are not permitted. ' +
      'Mini Connector enforces READ-ONLY mode. ' +
      'Attempted operation: ' + operation
    );
  }
}

// Intercept all query executions
const originalExecute = execute;
execute = function(query: string, ...args: any[]) {
  enforceReadOnly(query);
  return originalExecute(query, ...args);
};
    `;
  }
  
  private async parseDocumentation(
    docs: string,
    type: 'cloud' | 'on-premise'
  ): Promise<SDKSchema> {
    const prompt = `
Parse this API/database documentation and extract:

1. All available operations (functions/endpoints)
2. Authentication method
3. Request/response formats
4. Error handling
5. Rate limits
6. Connection requirements

${type === 'on-premise' ? `
IMPORTANT: This is for on-premise database access.
- Generate only SELECT queries (READ-ONLY)
- Do NOT generate INSERT, UPDATE, DELETE, DROP operations
- Include schema discovery queries
` : ''}

Documentation:
${docs}

Return ONLY valid JSON:
{
  "operations": [
    {
      "name": "...",
      "type": "read" | "write" | "admin",
      "description": "...",
      "parameters": [...],
      "returns": {...}
    }
  ],
  "authentication": {...},
  "connectionString": "...",
  "capabilities": ["bulk", "streaming", "transactions", ...]
}
    `;
    
    const response = await this.anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 8000,
      messages: [{ role: 'user', content: prompt }]
    });
    
    return JSON.parse(response.content[0].text);
  }
}
```

### 3.2 Mini Connector (Layer 2)

#### Architecture

**Technology Choices:**

- **Language:** Go (for .exe) or Node.js (for cross-platform)
- **Packaging:**
    - Windows: .exe (single file, no installation)
    - Linux: Binary or Docker
    - macOS: .app bundle

**Core Components:**

```go
// Mini Connector in Go
package main

import (
    "crypto/tls"
    "encoding/json"
    "github.com/gorilla/websocket"
    "time"
)

type MiniConnector struct {
    apiKey       string
    cloudURL     string
    conn         *websocket.Conn
    localVault   *CredentialVault
    executor     *QueryExecutor
    heartbeat    *time.Ticker
    commandQueue chan Command
}

func (mc *MiniConnector) Start() error {
    // 1. Load configuration
    config, err := mc.loadConfig()
    if err != nil {
        return err
    }
    
    // 2. Initialize local vault
    mc.localVault = NewCredentialVault(config.VaultPath)
    
    // 3. Connect to cloud via WebSocket
    dialer := websocket.Dialer{
        TLSClientConfig: &tls.Config{
            MinVersion: tls.VersionTLS13,
        },
    }
    
    conn, _, err := dialer.Dial(
        mc.cloudURL + "?apiKey=" + mc.apiKey,
        nil,
    )
    if err != nil {
        return err
    }
    mc.conn = conn
    
    // 4. Start heartbeat
    mc.startHeartbeat()
    
    // 5. Listen for commands
    go mc.listenForCommands()
    
    // 6. Process command queue
    go mc.processCommandQueue()
    
    return nil
}

func (mc *MiniConnector) listenForCommands() {
    for {
        var msg ServerMessage
        err := mc.conn.ReadJSON(&msg)
        if err != nil {
            log.Error("WebSocket read error:", err)
            mc.reconnect()
            continue
        }
        
        switch msg.Type {
        case "command":
            mc.commandQueue <- msg.Payload
            
        case "cancel":
            mc.executor.Cancel(msg.ExecutionID)
            
        case "shutdown":
            log.Info("Shutdown requested:", msg.Reason)
            mc.gracefulShutdown()
            return
        }
    }
}

func (mc *MiniConnector) processCommandQueue() {
    for cmd := range mc.commandQueue {
        // Execute command locally
        result, err := mc.executeCommand(cmd)
        
        // Send result back to cloud
        response := ClientMessage{
            Type: "execution_result",
            ExecutionID: cmd.ExecutionID,
            Result: result,
        }
        
        if err != nil {
            response.Type = "error"
            response.Error = err.Error()
        }
        
        mc.conn.WriteJSON(response)
    }
}

func (mc *MiniConnector) executeCommand(cmd Command) (interface{}, error) {
    // 1. Validate command
    if err := mc.validateCommand(cmd); err != nil {
        return nil, err
    }
    
    // 2. Get credentials from local vault
    creds, err := mc.localVault.Get(cmd.CredentialName)
    if err != nil {
        return nil, err
    }
    
    // 3. Execute query (READ-ONLY enforced)
    result, err := mc.executor.Execute(
        cmd.Operation,
        cmd.Params,
        creds,
        ExecutionOptions{
            ReadOnly: true, // ALWAYS READ-ONLY
            Timeout: cmd.Timeout,
        },
    )
    
    return result, err
}

func (mc *MiniConnector) startHeartbeat() {
    mc.heartbeat = time.NewTicker(30 * time.Second)
    go func() {
        for range mc.heartbeat.C {
            mc.conn.WriteJSON(ClientMessage{
                Type: "heartbeat",
            })
        }
    }()
}

func (mc *MiniConnector) reconnect() {
    backoff := time.Second
    maxBackoff := 5 * time.Minute
    
    for {
        log.Info("Attempting to reconnect...")
        
        conn, _, err := websocket.DefaultDialer.Dial(
            mc.cloudURL + "?apiKey=" + mc.apiKey,
            nil,
        )
        
        if err == nil {
            mc.conn = conn
            log.Info("Reconnected successfully")
            return
        }
        
        log.Error("Reconnect failed:", err)
        time.Sleep(backoff)
        
        backoff *= 2
        if backoff > maxBackoff {
            backoff = maxBackoff
        }
    }
}
```

#### Local Credential Vault

**Purpose:** Store database credentials locally (NEVER sent to cloud)

```go
type CredentialVault struct {
    path string
    key  []byte // Encryption key (derived from machine ID + API key)
}

func (v *CredentialVault) Store(name string, creds Credentials) error {
    // 1. Encrypt credentials
    encrypted, err := v.encrypt(creds)
    if err != nil {
        return err
    }
    
    // 2. Store in local file
    filepath := path.Join(v.path, name + ".enc")
    return ioutil.WriteFile(filepath, encrypted, 0600)
}

func (v *CredentialVault) Get(name string) (Credentials, error) {
    // 1. Read encrypted file
    filepath := path.Join(v.path, name + ".enc")
    encrypted, err := ioutil.ReadFile(filepath)
    if err != nil {
        return nil, err
    }
    
    // 2. Decrypt
    return v.decrypt(encrypted)
}

// Encryption uses machine-specific key
func (v *CredentialVault) deriveKey() []byte {
    machineID := getMachineID() // CPU ID + MAC address
    return pbkdf2.Key(
        []byte(v.apiKey + machineID),
        []byte("vansales-mini-connector"),
        100000,
        32,
        sha256.New,
    )
}
```

#### Configuration UI (Simple)

**Options:**

1. **CLI-based (initial):**

```bash
./mini-connector configure
> Enter API Key: xxxx-yyyy-zzzz
> Enter Cloud URL: wss://connector.vansales.com
> Enter Database Type: mysql
> Enter Host: localhost
> Enter Port: 3306
> Enter Username: root
> Enter Password: ****
> Test connection? [Y/n]: y
✓ Connection successful
✓ Schema discovered: 15 tables
✓ Configuration saved
```

2. **GUI-based (later):**
    - Electron app with system tray icon
    - Shows connection status
    - Logs last 100 commands
    - Manual credential update

#### Installation Package

**Structure:**

```
vansales-mini-connector-v1.0.0.zip
  ├── README.txt
  ├── mini-connector.exe (Windows)
  ├── mini-connector (Linux/macOS)
  ├── config.template.json
  └── docs/
      ├── installation.md
      ├── configuration.md
      └── troubleshooting.md
```

**config.template.json:**

```json
{
  "apiKey": "YOUR_API_KEY_HERE",
  "cloudURL": "wss://connector.vansales.com/ws",
  "database": {
    "type": "mysql",
    "host": "localhost",
    "port": 3306,
    "database": "erp_db",
    "username": "readonly_user",
    "password": "encrypted_will_be_prompted"
  },
  "options": {
    "autoReconnect": true,
    "heartbeatInterval": 30,
    "maxRetries": 10,
    "logLevel": "info"
  }
}
```

---

## 4. Data Flow Patterns

### Pattern 1: Cloud → On-Premise (Most Common)

**Scenario:** Salesforce → Local MySQL

```
1. User creates workflow in console:
   - Source: Salesforce (cloud aggregator)
   - Transform: Clean phone numbers
   - Destination: MySQL (mini connector)

2. Workflow execution triggered:
   
   [Console] Schedule workflow
   ↓
   [Control Plane] Start execution-12345
   ↓
   [Activity 1] Extract from Salesforce (direct API call)
   ↓
   [Data Buffer] Store extracted data (encrypted, 24h TTL)
   ↓
   [Activity 2] Transform data (cloud worker)
   ↓
   [Data Buffer] Update with transformed data
   ↓
   [Activity 3] Load to MySQL (mini connector)
   ↓
   [WebSocket Gateway] Send command to mini connector:
     {
       "type": "command",
       "commandId": "cmd-789",
       "payload": {
         "operation": "bulk_insert",
         "table": "customers",
         "data": "<buffer_key>", // Reference to buffer
         "idempotencyKey": "exec-12345:activity-3:attempt-1"
       }
     }
   ↓
   [Mini Connector] Receives command
   ↓
   [Mini Connector] Fetch data from buffer (via HTTPS):
     GET https://connector.vansales.com/api/v1/buffer/<buffer_key>
     Authorization: Bearer <api_key>
   ↓
   [Mini Connector] Decrypt and validate data
   ↓
   [Mini Connector] Execute local INSERT (READ-ONLY enforced for queries)
   ↓
   [Mini Connector] Send result to cloud:
     {
       "type": "execution_result",
       "executionId": "exec-12345",
       "activityId": "activity-3",
       "result": {
         "rowsInserted": 1000,
         "success": true
       }
     }
   ↓
   [Control Plane] Mark activity complete
   ↓
   [Control Plane] Mark workflow complete
   ↓
   [Data Buffer] Auto-purge after 24h
```

### Pattern 2: On-Premise → Cloud

**Scenario:** Local SAP → Snowflake

```
1. Workflow: SAP (mini connector) → Snowflake (cloud)

2. Execution:
   
   [Control Plane] Start execution
   ↓
   [Activity 1] Extract from SAP
   ↓
   [WebSocket Gateway] Send command to mini connector:
     {
       "operation": "execute_query",
       "query": "SELECT * FROM customers WHERE updated_at > ?",
       "params": ["2026-01-01"],
       "maxRows": 10000
     }
   ↓
   [Mini Connector] Execute local SELECT query
   ↓
   [Mini Connector] Stream results back to cloud:
     POST https://connector.vansales.com/api/v1/buffer/stream
     Authorization: Bearer <api_key>
     Content-Type: application/json
     
     Body: { rows: [...1000 rows...] }
     
   (Continues until all data sent)
   ↓
   [Data Buffer] Store in buffer
   ↓
   [Control Plane] Activity 1 complete
   ↓
   [Activity 2] Load to Snowflake (direct API)
   ↓
   [Control Plane] Workflow complete
```

### Pattern 3: On-Premise → On-Premise

**Scenario:** Local MySQL → Local PostgreSQL (same network, different mini connectors)

```
This is interesting because both are on-premise.

Solution: Data flows through cloud buffer as intermediary.

1. Workflow: MySQL (mini-connector-A) → PostgreSQL (mini-connector-B)

2. Execution:
   
   [Activity 1] Extract from MySQL
   ↓
   [Mini Connector A] Execute SELECT
   ↓
   [Mini Connector A] Upload to buffer
   ↓
   [Data Buffer] Store (encrypted)
   ↓
   [Activity 2] Load to PostgreSQL
   ↓
   [Mini Connector B] Download from buffer
   ↓
   [Mini Connector B] Execute INSERT
   ↓
   [Both connectors connected via WebSocket]
```

**Security Note:** Even though both databases are on same network, data goes through cloud buffer for:

- Audit trail
- Encryption
- Workflow orchestration
- Error handling

### Pattern 4: Schema Discovery

**Scenario:** User installs mini connector, system auto-discovers schema

```
1. Mini connector starts and connects to cloud

2. Cloud sends schema discovery command:
   {
     "type": "command",
     "operation": "discover_schema"
   }

3. Mini connector executes (database-specific):
   
   MySQL:
     SELECT 
       TABLE_NAME, 
       COLUMN_NAME, 
       DATA_TYPE, 
       IS_NULLABLE
     FROM INFORMATION_SCHEMA.COLUMNS
     WHERE TABLE_SCHEMA = 'erp_db'

   PostgreSQL:
     SELECT 
       table_name, 
       column_name, 
       data_type 
     FROM information_schema.columns
     WHERE table_schema = 'public'

   SAP HANA:
     SELECT * FROM SYS.TABLES
     SELECT * FROM SYS.COLUMNS

4. Mini connector sends schema to cloud:
   {
     "type": "schema_discovery",
     "schema": {
       "tables": [
         {
           "name": "customers",
           "columns": [
             { "name": "id", "type": "int", "nullable": false },
             { "name": "name", "type": "varchar", "nullable": true }
           ],
           "primaryKey": ["id"],
           "foreignKeys": [...]
         }
       ],
       "views": [...],
       "storedProcedures": [...]
     }
   }

5. Cloud stores schema in registry

6. AI uses schema for workflow suggestions:
   "I see you have a 'customers' table with 'email' column.
    Would you like to sync this to Mailchimp?"
```

---

## 5. Security Model

### 5.1 Credential Isolation

**Key Principle:** Credentials NEVER leave the on-premise network

```
┌──────────────────────────────────────────────────────┐
│                   Cloud Console                       │
│                                                       │
│  ❌ NO database credentials stored                   │
│  ❌ NO connection strings                            │
│  ❌ NO passwords                                     │
│                                                       │
│  ✅ Only API keys (for mini connector auth)         │
│  ✅ Only temporary data (in buffer, encrypted)       │
└──────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────┐
│                  Mini Connector                       │
│                                                       │
│  ✅ Database credentials stored locally              │
│  ✅ Encrypted with machine-specific key              │
│  ✅ Never transmitted to cloud                       │
│  ✅ Decrypted only in memory during query execution  │
└──────────────────────────────────────────────────────┘
```

**Implementation:**

```typescript
// Cloud never stores credentials
interface TenantAggregator {
  id: string;
  tenantId: string;
  aggregatorId: string;
  
  // For cloud aggregators only
  cloudCredentials?: {
    apiKey?: string;
    accessToken?: string;
    // Stored in Vault, encrypted
  };
  
  // For on-premise (mini connector)
  miniConnector?: {
    apiKey: string; // Cloud → Mini connector auth
    status: 'connected' | 'disconnected';
    lastSeen: Date;
    schemaDiscovered: boolean;
    // NO DATABASE CREDENTIALS HERE
  };
}
```

### 5.2 READ-ONLY Enforcement (Multi-Layer)

**Layer 1: SDK Generation (AI-level)**

- AI generates only SELECT queries
- No INSERT/UPDATE/DELETE in generated code

**Layer 2: WASM Sandbox (Runtime)**

```typescript
// Injected into WASM SDK
function enforceReadOnly(query: string) {
  const operation = query.trim().toUpperCase().split(' ')[0];
  
  const ALLOWED = ['SELECT', 'SHOW', 'DESCRIBE', 'EXPLAIN', 'USE'];
  const FORBIDDEN = ['INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 
                     'ALTER', 'TRUNCATE', 'GRANT', 'REVOKE'];
  
  if (FORBIDDEN.includes(operation)) {
    throw new SecurityError(
      `Operation ${operation} is forbidden in READ-ONLY mode`
    );
  }
  
  if (!ALLOWED.includes(operation)) {
    // Log suspicious query for review
    await auditLog.warn({
      event: 'suspicious_query',
      query: query.substring(0, 100)
    });
    throw new SecurityError('Query not allowed');
  }
}
```

**Layer 3: Mini Connector (Local enforcement)**

```go
func (e *QueryExecutor) Execute(
    query string, 
    params []interface{}, 
    creds Credentials,
    opts ExecutionOptions,
) (interface{}, error) {
    // CRITICAL: Enforce read-only even if opts say otherwise
    if opts.ReadOnly || e.config.AlwaysReadOnly {
        if !isReadOnlyQuery(query) {
            return nil, fmt.Errorf(
                "Write operation not permitted: %s",
                strings.Split(query, " ")[0],
            )
        }
    }
    
    // Execute query...
}

func isReadOnlyQuery(query string) bool {
    operation := strings.ToUpper(strings.TrimSpace(query))
    
    readOnlyPrefixes := []string{
        "SELECT", "SHOW", "DESCRIBE", "EXPLAIN",
    }
    
    for _, prefix := range readOnlyPrefixes {
        if strings.HasPrefix(operation, prefix) {
            return true
        }
    }
    
    return false
}
```

**Layer 4: Database User (Best practice recommendation)**

```sql
-- Create read-only database user
CREATE USER 'connector_readonly'@'localhost' 
IDENTIFIED BY 'secure_password';

GRANT SELECT ON erp_db.* TO 'connector_readonly'@'localhost';

-- Verify permissions
SHOW GRANTS FOR 'connector_readonly'@'localhost';
-- Output: GRANT SELECT ON `erp_db`.* TO 'connector_readonly'@'localhost'
```

### 5.3 API Key Security

**Generation:**

```typescript
class APIKeyService {
  async generateForMiniConnector(
    tenantId: string,
    name: string
  ): Promise<string> {
    // Format: vmc_<tenant_prefix>_<random>_<checksum>
    // Example: vmc_abc123_x7f9k2p5w8q1_c4e2a
    
    const prefix = 'vmc'; // Vansales Mini Connector
    const tenantPrefix = tenantId.substring(0, 6);
    const random = crypto.randomBytes(16).toString('hex');
    const checksum = crypto
      .createHash('sha256')
      .update(tenantPrefix + random + process.env.API_KEY_SECRET)
      .digest('hex')
      .substring(0, 5);
    
    const apiKey = `${prefix}_${tenantPrefix}_${random}_${checksum}`;
    
    // Store hash (not plaintext)
    await this.db.apiKeys.create({
      tenantId,
      name,
      keyHash: this.hash(apiKey),
      type: 'mini_connector',
      permissions: ['connect', 'execute', 'buffer_access'],
      createdAt: new Date(),
      expiresAt: null, // No expiration (but can be revoked)
      revokedAt: null
    });
    
    return apiKey; // Show to user ONCE, never again
  }
  
  async validate(apiKey: string): Promise<APIKeyConfig> {
    // 1. Check format
    if (!apiKey.startsWith('vmc_')) {
      throw new Error('Invalid API key format');
    }
    
    // 2. Verify checksum
    const parts = apiKey.split('_');
    if (parts.length !== 4) {
      throw new Error('Invalid API key structure');
    }
    
    const [prefix, tenantPrefix, random, checksum] = parts;
    const expectedChecksum = crypto
      .createHash('sha256')
      .update(tenantPrefix + random + process.env.API_KEY_SECRET)
      .digest('hex')
      .substring(0, 5);
    
    if (checksum !== expectedChecksum) {
      throw new Error('Invalid API key checksum');
    }
    
    // 3. Lookup in database
    const keyHash = this.hash(apiKey);
    const config = await this.db.apiKeys.findOne({
      where: { keyHash, type: 'mini_connector' }
    });
    
    if (!config) {
      throw new Error('API key not found');
    }
    
    // 4. Check if revoked
    if (config.revokedAt) {
      throw new Error('API key has been revoked');
    }
    
    // 5. Check expiration (if set)
    if (config.expiresAt && new Date() > config.expiresAt) {
      throw new Error('API key expired');
    }
    
    return config;
  }
  
  // Emergency revoke (e.g., if key leaked)
  async revoke(apiKey: string, reason: string): Promise<void> {
    const keyHash = this.hash(apiKey);
    
    await this.db.apiKeys.update({
      where: { keyHash },
      data: {
        revokedAt: new Date(),
        revokeReason: reason
      }
    });
    
    // Disconnect any active mini connector using this key
    await this.websocketGateway.disconnectByAPIKey(apiKey);
    
    await this.auditLog.log({
      action: 'api_key_revoked',
      apiKey: apiKey.substring(0, 12) + '***',
      reason
    });
  }
}
```

### 5.4 Data Buffer Security

**Encryption:**

```typescript
class BufferEncryption {
  async encrypt(tenantId: string, data: any): Promise<Buffer> {
    // 1. Get tenant's encryption key from KMS
    const dek = await this.getTenantDEK(tenantId);
    
    // 2. Generate IV
    const iv = crypto.randomBytes(16);
    
    // 3. Encrypt with AES-256-GCM
    const cipher = crypto.createCipheriv('aes-256-gcm', dek.key, iv);
    const encrypted = Buffer.concat([
      cipher.update(JSON.stringify(data), 'utf8'),
      cipher.final()
    ]);
    
    const authTag = cipher.getAuthTag();
    
    // 4. Combine: IV + AuthTag + Encrypted Data
    return Buffer.concat([iv, authTag, encrypted]);
  }
  
  async decrypt(tenantId: string, encrypted: Buffer): Promise<any> {
    // 1. Extract components
    const iv = encrypted.slice(0, 16);
    const authTag = encrypted.slice(16, 32);
    const ciphertext = encrypted.slice(32);
    
    // 2. Get tenant's encryption key
    const dek = await this.getTenantDEK(tenantId);
    
    // 3. Decrypt
    const decipher = crypto.createDecipheriv('aes-256-gcm', dek.key, iv);
    decipher.setAuthTag(authTag);
    
    const decrypted = Buffer.concat([
      decipher.update(ciphertext),
      decipher.final()
    ]);
    
    return JSON.parse(decrypted.toString('utf8'));
  }
  
  private async getTenantDEK(tenantId: string): Promise<DEK> {
    // Cached for 5 minutes
    const cached = await this.cache.get(`dek:${tenantId}`);
    if (cached) return cached;
    
    // Fetch encrypted DEK from database
    const encryptedDEK = await this.db.getTenantDEK(tenantId);
    
    // Decrypt using AWS KMS master key
    const decrypted = await this.kms.decrypt({
      CiphertextBlob: encryptedDEK,
      KeyId: process.env.KMS_MASTER_KEY_ARN
    });
    
    await this.cache.set(`dek:${tenantId}`, decrypted, 300);
    return decrypted;
  }
}
```

**Access Control:**

```typescript
// Only the mini connector with matching tenant can access buffer
async getBufferData(apiKey: string, bufferKey: string): Promise<any> {
  // 1. Validate API key
  const config = await this.apiKeyService.validate(apiKey);
  
  // 2. Extract tenant ID from buffer key
  // Format: tenants/{tenant_id}/workflows/{workflow_id}/...
  const tenantId = bufferKey.split('/')[1];
  
  // 3. Verify API key belongs to same tenant
  if (config.tenantId !== tenantId) {
    throw new Error('Access denied: API key does not match tenant');
  }
  
  // 4. Retrieve and decrypt
  const encrypted = await this.s3.getObject({
    Bucket: 'vansales-buffer',
    Key: bufferKey
  });
  
  const decrypted = await this.encryption.decrypt(tenantId, encrypted.Body);
  
  // 5. Audit log
  await this.auditLog.log({
    tenantId,
    action: 'buffer_data_accessed',
    apiKey: apiKey.substring(0, 12) + '***',
    bufferKey
  });
  
  return decrypted;
}
```

### 5.5 WebSocket Security

**TLS 1.3 Only:**

```typescript
const server = createServer({
  cert: fs.readFileSync('cert.pem'),
  key: fs.readFileSync('key.pem'),
  minVersion: 'TLSv1.3', // Force TLS 1.3
  ciphers: [
    'TLS_AES_256_GCM_SHA384',
    'TLS_CHACHA20_POLY1305_SHA256'
  ].join(':')
});
```

**Authentication:**

```typescript
wsServer.on('connection', async (socket, request) => {
  // 1. Extract API key from query string or header
  const apiKey = new URL(request.url, 'wss://dummy').searchParams.get('apiKey')
    || request.headers['x-api-key'];
  
  if (!apiKey) {
    socket.send(JSON.stringify({ error: 'Missing API key' }));
    socket.close(4000, 'Authentication required');
    return;
  }
  
  // 2. Validate API key
  try {
    const config = await apiKeyService.validate(apiKey);
    
    // 3. Check for duplicate connection
    if (connectionRegistry.has(apiKey)) {
      socket.send(JSON.stringify({
        error: 'API key already in use. Only one connection per key allowed.'
      }));
      socket.close(4001, 'Duplicate connection');
      return;
    }
    
    // 4. Register connection
    connectionRegistry.set(apiKey, {
      socket,
      tenantId: config.tenantId,
      connectedAt: new Date()
    });
    
    socket.send(JSON.stringify({
      type: 'connected',
      message: 'Authentication successful'
    }));
    
  } catch (error) {
    socket.send(JSON.stringify({ error: error.message }));
    socket.close(4002, 'Authentication failed');
  }
});
```

**Rate Limiting:**

```typescript
class WebSocketRateLimiter {
  private limits = new Map<string, {
    commands: number,
    windowStart: number
  }>();
  
  async checkLimit(apiKey: string): Promise<void> {
    const now = Date.now();
    const windowSize = 60000; // 1 minute
    const maxCommands = 100; // 100 commands per minute
    
    let record = this.limits.get(apiKey);
    
    if (!record || now - record.windowStart > windowSize) {
      record = { commands: 0, windowStart: now };
    }
    
    record.commands++;
    this.limits.set(apiKey, record);
    
    if (record.commands > maxCommands) {
      throw new Error('Rate limit exceeded: max 100 commands per minute');
    }
  }
}
```

---

## 6. Implementation Plan (Updated)

### Phase 1: Foundation + Mini Connector (Months 1-3)

#### Month 1: Cloud Infrastructure

**Week 1-2:**

- Monorepo setup (NX/Turborepo)
- Database schema (PostgreSQL)
- Tenant management API
- API key generation service

**Week 3-4:**

- WebSocket gateway (initial implementation)
- Connection registry (Redis-backed)
- Heartbeat monitor
- Basic command routing

#### Month 2: Mini Connector Development

**Week 1-2:**

- Mini connector core (Go or Node.js)
- WebSocket client
- Reconnection logic
- Local credential vault

**Week 3-4:**

- Query executor (MySQL, PostgreSQL)
- READ-ONLY enforcement
- Schema discovery
- Configuration CLI

**Deliverables:**

- `mini-connector.exe` (Windows)
- `mini-connector` (Linux/macOS binary)
- Configuration tool
- Installation documentation

#### Month 3: Data Buffer + Basic Workflows

**Week 1-2:**

- S3-based data buffer
- Encryption service (per-tenant DEKs)
- Auto-purge mechanism
- Buffer access API

**Week 3-4:**

- Basic workflow engine
- Activity types: extract, transform, load
- Mini connector integration
- End-to-end test: Cloud → Mini Connector → Local DB

**Milestone:** Can sync Salesforce → Local MySQL via mini connector

### Phase 2: AI SDK Generator (Months 4-5)

#### Month 4: Documentation Parser

**Week 1-2:**

- AI documentation parser (Claude)
- Schema extraction
- Operation identification
- Cloud vs on-premise detection

**Week 3-4:**

- TypeScript SDK code generation
- READ-ONLY enforcement injection
- WASM compilation
- Security scanning

#### Month 5: Aggregator Marketplace

**Week 1-2:**

- Marketplace UI (React)
- Aggregator listing
- Installation flow
- SDK status tracking

**Week 3-4:**

- Schema discovery integration
- AI-powered workflow suggestions
- Table mapping assistant
- Testing framework

**Milestone:** Can generate SDK from any API documentation

### Phase 3: Production UI (Months 6-7)

#### Month 6: Workflow Designer

**Week 1-4:**

- React Flow-based designer
- Drag-and-drop activities
- Property inspector
- Aggregator selection
- Real-time validation

#### Month 7: Monitoring Dashboard

**Week 1-4:**

- Execution list view
- Execution detail with timeline
- Mini connector status dashboard
- Error explorer
- Control panel (pause/cancel/resume)

**Milestone:** Full user-facing product ready

### Phase 4: Production Hardening (Months 8-9)

#### Month 8: Security & Compliance

**Week 1-2:**

- Penetration testing
- Security audit
- SAST/DAST in CI/CD
- Secrets scanning

**Week 3-4:**

- SOC 2 Type II prep
- Audit logging completion
- Incident response plan
- Compliance documentation

#### Month 9: Observability & Operations

**Week 1-2:**

- Prometheus metrics
- Grafana dashboards
- OpenTelemetry tracing
- Alerting rules

**Week 3-4:**

- Control flags UI
- Health checks
- Backup/restore procedures
- Disaster recovery plan

**Milestone:** Production-ready

### Phase 5: Scale & Polish (Months 10-12)

#### Month 10: Performance Optimization

**Week 1-4:**

- Load testing (10K concurrent workflows)
- Database optimization
- WebSocket scaling (cluster mode)
- Worker autoscaling

#### Month 11: Enterprise Features

**Week 1-4:**

- Multi-region support
- Custom aggregators (customer-uploaded)
- Advanced transformations
- Workflow templates

#### Month 12: Launch Preparation

**Week 1-4:**

- Beta testing (10 customers)
- Documentation polish
- Video tutorials
- Marketing materials

**Milestone:** General availability launch

---

## 7. Technology Stack (Updated)

### Cloud Console

```yaml
Backend:
  Language: TypeScript
  Runtime: Node.js 20 LTS
  Framework: NestJS
  API: REST + GraphQL
  WebSocket: Socket.io or ws library
  
Database:
  Primary: PostgreSQL 15+
  Cache: Redis 7+
  Object Storage: AWS S3 or compatible
  Secrets: HashiCorp Vault
  
Queue:
  Phase 1: BullMQ + Redis
  Phase 2: Temporal (migration ready)
  
Frontend:
  Framework: React 18 + TypeScript
  Workflow Designer: React Flow (xyflow)
  State: Zustand
  Data Fetching: TanStack Query
  UI: shadcn/ui
  Real-time: Socket.io client
  
AI:
  Provider: Anthropic Claude (Sonnet 4)
  SDK: @anthropic-ai/sdk
  Use Cases:
    - Documentation parsing
    - SDK generation
    - Workflow generation
    - Schema understanding
  
Observability:
  Metrics: Prometheus
  Dashboards: Grafana
  Tracing: OpenTelemetry
  Logging: Loki or ELK
```

### Mini Connector

```yaml
Option 1 (Recommended): Go
  Advantages:
    - Single binary (no runtime needed)
    - Small size (~10-20MB)
    - Fast execution
    - Cross-platform compilation
    - Excellent WebSocket libraries
  
  Stack:
    - WebSocket: gorilla/websocket
    - Database: database/sql + drivers
    - Encryption: crypto/aes, crypto/tls
    - Config: viper
  
  Build:
    GOOS=windows GOARCH=amd64 go build -o mini-connector.exe
    GOOS=linux GOARCH=amd64 go build -o mini-connector
    GOOS=darwin GOARCH=amd64 go build -o mini-connector

Option 2 (Alternative): Node.js
  Advantages:
    - Same language as cloud (TypeScript)
    - Rich ecosystem
    - Easier for team familiar with Node
  
  Disadvantages:
    - Requires Node.js runtime on target machine
    - Larger package size
  
  Packaging:
    - pkg or nexe (compile to exe)
    - Or ship with node runtime

Decision: Go for production, Node.js for MVP
```

### Database Support (Mini Connector)

```yaml
Phase 1 (MVP):
  - MySQL 5.7+
  - PostgreSQL 12+
  - Microsoft SQL Server 2016+

Phase 2:
  - Oracle Database 12c+
  - SAP HANA
  - MongoDB (read-only views)

Phase 3:
  - Tally ERP (via ODBC)
  - Custom ODBC/JDBC connectors
```

---

## 8. Critical Design Decisions

### 8.1 Why Outbound WebSocket (Not HTTP Polling)?

|Approach|Pros|Cons|Decision|
|---|---|---|---|
|**HTTP Polling**|Simple, stateless|High latency, inefficient|❌|
|**HTTP Long Polling**|Better than polling|Connection timeouts, complex|❌|
|**Outbound WebSocket**|Real-time, efficient, firewall-friendly|Stateful, requires reconnection logic|✅ **CHOSEN**|
|**Inbound connections**|Simple architecture|Requires static IP, firewall rules|❌ **NOT FEASIBLE**|

**Why WebSocket Wins:**

1. Initiates connection from inside firewall (no inbound rules needed)
2. Persistent connection (low latency for commands)
3. Bidirectional (cloud can send commands, mini connector can stream data)
4. Standard protocol (well-supported libraries)
5. Works through corporate proxies (with HTTPS tunneling)

### 8.2 Why Data Buffer (Not Direct Streaming)?

**Considered:** Mini Connector → Cloud → Destination (direct streaming)

**Problem:**

- What if destination is slow/unavailable?
- What if transformation takes time?
- How to retry on failure?

**Solution:** Temporary buffer as intermediary

**Benefits:**

1. **Decoupling:** Source and destination don't need to be available simultaneously
2. **Retry:** Can retry loading without re-extracting
3. **Transformation:** Can transform data in cloud without blocking mini connector
4. **Audit:** Full data trail for debugging
5. **Security:** Data encrypted at rest, auto-purged

**Trade-off:** Extra storage cost (acceptable, data is short-lived)

### 8.3 Why One API Key Per Connector (Not Multi-Use)?

**Boss's Requirement:** "1 API key for one connector, if another connector tries to connect with the same API key, it throws an error"

**Reasoning:**

1. **Security:** Prevents key sharing between companies
2. **Accountability:** Clear audit trail per installation
3. **Control:** Can revoke specific installation without affecting others
4. **Monitoring:** Track health per connector instance

**Implementation:**

```typescript
const connectionRegistry = new Map<string, WebSocketConnection>();

async onConnect(socket: WebSocket, apiKey: string) {
  if (connectionRegistry.has(apiKey)) {
    throw new Error('API key already in use');
  }
  
  connectionRegistry.set(apiKey, { socket, ... });
}
```

### 8.4 Why READ-ONLY Default (Even with Root Credentials)?

**Boss's Requirement:** "DB access with read access by default, even with root access it need only be on read mode"

**Reasoning:**

1. **Safety:** Prevents accidental data corruption
2. **Compliance:** Many regulations require read-only integrations
3. **Trust:** Customers more willing to share credentials if read-only
4. **Write via API:** If writes needed, company exposes API (not direct DB access)

**Multi-Layer Enforcement:**

```
Layer 1: AI generates only SELECT
Layer 2: WASM runtime blocks writes
Layer 3: Mini connector validates queries
Layer 4: Database user has only SELECT grants (recommended)
```

**Escape Hatch:** For trusted customers, we can:

1. Allow write operations via separate API endpoints (not direct DB)
2. Require explicit "enable writes" checkbox + legal agreement
3. Log ALL write operations extensively

### 8.5 Why Schema Discovery (Not Manual Mapping)?

**User Experience:**

```
Manual:
1. User installs mini connector
2. User opens console
3. User manually types table names
4. User manually types column names
5. User creates mappings

Auto-Discovery:
1. User installs mini connector
2. Console: "I found 15 tables. Would you like to sync 'customers' to Salesforce?"
```

**Benefits:**

1. **Faster onboarding:** 2 minutes vs 30 minutes
2. **Fewer errors:** No typos in table/column names
3. **AI suggestions:** "I see you have email addresses, want to sync to Mailchimp?"
4. **Relationship understanding:** AI can see foreign keys and suggest JOIN workflows

---

## 9. Production Checklist (Updated)

### 9.1 Cloud Console

- [ ] Multi-tenant isolation complete
    - [ ] Schema-per-tenant working
    - [ ] Resource quotas enforced
    - [ ] Tier-based queue sharding
- [ ] WebSocket Gateway production-ready
    - [ ] TLS 1.3 only
    - [ ] Connection registry (Redis-backed)
    - [ ] Heartbeat monitoring
    - [ ] Reconnection handling
    - [ ] Rate limiting (100 commands/min per connector)
    - [ ] Duplicate connection prevention
- [ ] Data Buffer secure
    - [ ] Per-tenant encryption keys
    - [ ] Auto-purge after 24h
    - [ ] Access control (API key validation)
    - [ ] Audit logging
- [ ] API Key Management
    - [ ] Secure generation (crypto.randomBytes)
    - [ ] Hash storage (never plaintext)
    - [ ] Checksum validation
    - [ ] Revocation mechanism
    - [ ] Emergency kill switch
- [ ] AI SDK Generator
    - [ ] Documentation parsing working
    - [ ] Code generation tested
    - [ ] READ-ONLY enforcement injected
    - [ ] Security scanning integrated
    - [ ] WASM compilation working
- [ ] Workflow Engine
    - [ ] Activity execution idempotent
    - [ ] State persistence complete
    - [ ] Retry logic working
    - [ ] Cancellation support
    - [ ] Mini connector integration tested
- [ ] Observability
    - [ ] Prometheus metrics
    - [ ] Grafana dashboards
    - [ ] OpenTelemetry tracing
    - [ ] Audit logging
    - [ ] Alerting rules
- [ ] Security
    - [ ] SAST/DAST in CI/CD
    - [ ] Secrets scanning
    - [ ] Penetration testing complete
    - [ ] Vulnerability scanning automated
    - [ ] Incident response plan documented

### 9.2 Mini Connector

- [ ] Binary builds
    - [ ] Windows .exe (tested on Win 10, Win 11)
    - [ ] Linux binary (Ubuntu, CentOS)
    - [ ] macOS binary (Intel, Apple Silicon)
- [ ] WebSocket Client
    - [ ] TLS 1.3 support
    - [ ] Automatic reconnection
    - [ ] Exponential backoff
    - [ ] Heartbeat sending
    - [ ] Command queue (offline buffering)
- [ ] Local Credential Vault
    - [ ] Encryption with machine-specific key
    - [ ] Secure storage
    - [ ] Never transmitted to cloud
    - [ ] Config file protection (0600 permissions)
- [ ] Query Executor
    - [ ] MySQL support
    - [ ] PostgreSQL support
    - [ ] SQL Server support
    - [ ] READ-ONLY enforcement
    - [ ] Query timeout (30s default)
    - [ ] Connection pooling
- [ ] Schema Discovery
    - [ ] INFORMATION_SCHEMA queries
    - [ ] Table/column metadata
    - [ ] Primary/foreign keys
    - [ ] Error handling
- [ ] Configuration
    - [ ] CLI setup wizard
    - [ ] Config file validation
    - [ ] Test connection command
    - [ ] Verbose logging (debug mode)
- [ ] Installation Package
    - [ ] README.txt
    - [ ] Configuration template
    - [ ] Installation guide
    - [ ] Troubleshooting guide
- [ ] Testing
    - [ ] Unit tests (80%+ coverage)
    - [ ] Integration tests (with cloud)
    - [ ] Reconnection tests
    - [ ] Failure scenarios (network loss, DB down)
    - [ ] Load testing (1000 concurrent queries)

### 9.3 End-to-End

- [ ] Data Flow Tests
    - [ ] Cloud → On-premise (Salesforce → MySQL)
    - [ ] On-premise → Cloud (MySQL → Snowflake)
    - [ ] On-premise → On-premise (MySQL → PostgreSQL)
    - [ ] Hybrid workflows (multi-hop)
- [ ] Error Handling
    - [ ] Network timeout
    - [ ] Database unavailable
    - [ ] Mini connector offline
    - [ ] Invalid credentials
    - [ ] Buffer full
    - [ ] Query timeout
- [ ] Security Tests
    - [ ] SQL injection attempts (should fail)
    - [ ] Write operations (should be blocked)
    - [ ] Unauthorized buffer access (should fail)
    - [ ] Duplicate API key connection (should fail)
    - [ ] Credential leakage tests
- [ ] Performance Tests
    - [ ] 10,000 row extraction
    - [ ] 100 concurrent mini connectors
    - [ ] Sustained load (24h)
    - [ ] Reconnection under load
    - [ ] Buffer throughput
- [ ] Compliance
    - [ ] Audit logs complete
    - [ ] Data retention policy
    - [ ] GDPR compliance (if EU customers)
    - [ ] SOC 2 controls implemented

---

## 10. Risk Assessment (Updated)

### 10.1 Technical Risks

|Risk|Probability|Impact|Mitigation|
|---|---|---|---|
|WebSocket scalability limits|MEDIUM|HIGH|Use WebSocket cluster mode, Redis pub/sub for broadcasting|
|Mini connector offline during execution|HIGH|MEDIUM|Command queuing, retry logic, clear error messages|
|Network instability (reconnections)|HIGH|LOW|Exponential backoff, resume from checkpoint|
|On-premise firewall blocks WebSocket|MEDIUM|HIGH|Support HTTP tunneling, provide firewall documentation|
|Database connection exhaustion|MEDIUM|HIGH|Connection pooling, timeouts, per-tenant limits|
|READ-ONLY bypass attempts|LOW|CRITICAL|Multi-layer enforcement, audit logging|
|API key leakage|MEDIUM|HIGH|Revocation mechanism, rotation policy, monitoring|
|Data buffer overflow|LOW|MEDIUM|Auto-purge, size limits, alerting|
|Schema discovery fails|MEDIUM|LOW|Manual fallback, retry logic|
|WASM compilation failure|LOW|MEDIUM|Node.js VM fallback, error reporting|

### 10.2 Business Risks

|Risk|Probability|Impact|Mitigation|
|---|---|---|---|
|Customers don't trust cloud|MEDIUM|HIGH|Emphasize credential never leave premises, SOC 2 cert|
|Mini connector installation friction|MEDIUM|HIGH|One-click installer, clear documentation, video guide|
|Slow customer adoption|MEDIUM|HIGH|Free tier, excellent docs, beta program|
|Competition (Zapier, etc.)|HIGH|MEDIUM|Differentiation: AI-powered, ERP-focused, on-premise support|
|Sales cycle longer than expected|MEDIUM|MEDIUM|Target SMBs first (faster decisions)|
|Support burden (firewall issues)|HIGH|MEDIUM|Self-service troubleshooting, common issue database|

### 10.3 Security Risks

|Risk|Probability|Impact|Mitigation|
|---|---|---|---|
|Credential theft from mini connector|LOW|CRITICAL|Encrypted vault, machine-specific key, no cloud transmission|
|Man-in-the-middle attack|LOW|CRITICAL|TLS 1.3 only, certificate pinning (optional)|
|Malicious mini connector binary|LOW|CRITICAL|Code signing, checksum verification|
|SQL injection via SDK|LOW|HIGH|Parameterized queries only, WASM sandbox|
|Data breach in buffer|LOW|CRITICAL|Encryption at rest, short TTL, access controls|
|Insider threat (employee)|LOW|HIGH|RBAC, audit logging, least privilege|

---

## Conclusion

### What Changed from Original Architecture

|Aspect|Original|Revised|
|---|---|---|
|**Connection Model**|Cloud directly accesses ERP|Mini connector bridges on-premise and cloud|
|**Credential Storage**|Cloud stores credentials|Credentials never leave on-premise network|
|**Network Requirements**|Static IP, inbound firewall rules|Outbound WebSocket only (firewall-friendly)|
|**Data Flow**|Direct execution|Via encrypted temporary buffer|
|**Target Market**|Cloud-only ERPs|All ERPs (cloud + on-premise)|
|**Installation**|None|Download and configure mini connector|

### Why This Design Works

1. **Firewall-Friendly:** Outbound WebSocket works in 99% of corporate networks
2. **Secure:** Credentials never transmitted, multi-layer READ-ONLY enforcement
3. **Scalable:** WebSocket cluster mode, Redis-backed registry
4. **Reliable:** Reconnection logic, command queuing, idempotent execution
5. **User-Friendly:** Auto schema discovery, AI suggestions, simple configuration
6. **Flexible:** Supports cloud-to-cloud, cloud-to-on-premise, on-premise-to-on-premise

### Success Criteria

**MVP (Month 6):**

- [ ] 5 beta customers using mini connector
- [ ] 3 database types supported (MySQL, PostgreSQL, SQL Server)
- [ ] 10 workflows running in production
- [ ] 99% uptime for WebSocket gateway
- [ ] <5s command latency (cloud → mini connector)

**Production (Month 12):**

- [ ] 50 paying customers
- [ ] 5000+ mini connectors deployed
- [ ] 10,000 workflows/day
- [ ] 99.9% uptime
- [ ] 5 ERP types supported
- [ ] SOC 2 Type II certified

**Scale (Month 18):**

- [ ] 200+ customers
- [ ] 50,000+ mini connectors
- [ ] 100,000+ workflows/day
- [ ] Multi-region deployment
- [ ] Support 20+ ERP types

---

## Appendices

### Appendix A: Mini Connector Installation Guide

```bash
# 1. Download mini connector
wget https://downloads.vansales.com/mini-connector/v1.0.0/mini-connector-linux-amd64

# 2. Make executable
chmod +x mini-connector-linux-amd64

# 3. Run configuration wizard
./mini-connector-linux-amd64 configure

> Enter API Key: vmc_abc123_x7f9k2p5w8q1_c4e2a
> Enter Database Type: mysql
> Enter Host: localhost
> Enter Port: 3306
> Enter Database: erp_db
> Enter Username: readonly_user
> Enter Password: ********

> Testing connection...
✓ Connection successful
✓ Schema discovered: 15 tables
✓ Configuration saved to /etc/vansales/mini-connector/config.json

# 4. Start mini connector
./mini-connector-linux-amd64 start

> Connecting to wss://connector.vansales.com...
✓ Connected
✓ Authenticated as Tenant: ABC Corp
✓ Ready to receive commands

# 5. (Optional) Install as system service
sudo ./mini-connector-linux-amd64 install-service
sudo systemctl start vansales-mini-connector
sudo systemctl enable vansales-mini-connector
```

### Appendix B: WebSocket Protocol Specification

**Client → Server (Mini Connector → Cloud):**

```json
// 1. Heartbeat (every 30s)
{
  "type": "heartbeat",
  "timestamp": "2026-01-29T10:30:00Z"
}

// 2. Execution Result
{
  "type": "execution_result",
  "executionId": "exec-12345",
  "activityId": "activity-1",
  "commandId": "cmd-789",
  "result": {
    "success": true,
    "rowsAffected": 1000,
    "data": "<buffer_key>" // or inline if small
  },
  "timestamp": "2026-01-29T10:30:15Z"
}

// 3. Error
{
  "type": "error",
  "executionId": "exec-12345",
  "activityId": "activity-1",
  "commandId": "cmd-789",
  "error": {
    "code": "QUERY_TIMEOUT",
    "message": "Query execution exceeded 30s timeout",
    "retryable": true
  },
  "timestamp": "2026-01-29T10:30:45Z"
}

// 4. Schema Discovery
{
  "type": "schema_discovery",
  "schema": {
    "tables": [
      {
        "name": "customers",
        "columns": [
          { "name": "id", "type": "int", "nullable": false },
          { "name": "name", "type": "varchar(255)", "nullable": true }
        ],
        "primaryKey": ["id"]
      }
    ]
  },
  "timestamp": "2026-01-29T10:25:00Z"
}

// 5. Status Update
{
  "type": "status",
  "status": "ready" | "busy" | "error",
  "activeCommands": 0,
  "timestamp": "2026-01-29T10:30:00Z"
}
```

**Server → Client (Cloud → Mini Connector):**

```json
// 1. Connected
{
  "type": "connected",
  "tenantId": "abc123",
  "message": "Mini Connector authenticated successfully"
}

// 2. Command
{
  "type": "command",
  "commandId": "cmd-789",
  "executionId": "exec-12345",
  "activityId": "activity-1",
  "operation": "execute_query",
  "payload": {
    "query": "SELECT * FROM customers WHERE created_at > ?",
    "params": ["2026-01-01"],
    "timeout": 30000,
    "idempotencyKey": "exec-12345:activity-1:attempt-1"
  }
}

// 3. Cancel
{
  "type": "cancel",
  "executionId": "exec-12345",
  "reason": "User cancelled workflow"
}

// 4. Shutdown
{
  "type": "shutdown",
  "reason": "System maintenance",
  "gracePeriod": 60000 // 60 seconds
}

// 5. Error (from server)
{
  "type": "error",
  "code": "DUPLICATE_CONNECTION",
  "message": "API key already in use. Only one connection per key allowed."
}
```

---

**Document Version:** 2.0 (REVISED)  
**Last Updated:** January 29, 2026  
**Next Review:** February 15, 2026

**Author:** Claude (Anthropic AI)  
**Reviewed By:** [Boss Name]  
**Status:** Ready for Engineering Review